{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1b62941",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57432999",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # ilkleme\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adım 1 - Convolution\n",
    "classifier.add(Convolution2D(32, 3, 3, input_shape = (64, 64, 3), activation = 'relu'))\n",
    "\n",
    "# Adım 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# 2. convolution katmanı\n",
    "classifier.add(Convolution2D(32, 3, 3, activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Adım 3 - Flattening\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbe550a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adım 4 - YSA\n",
    "classifier.add(Dense(units=128, activation='relu'))\n",
    "classifier.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "857de054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2662 images belonging to 2 classes.\n",
      "Found 203 images belonging to 2 classes.\n",
      "2662/2662 [==============================] - 17s 6ms/step - loss: 0.4364 - accuracy: 0.7810 - val_loss: 0.3021 - val_accuracy: 0.7931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dbf0a37150>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNN ve resimler\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('veriler/training_set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 1,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('veriler/test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 1,\n",
    "                                            class_mode = 'binary')\n",
    "\n",
    "classifier.fit(training_set,\n",
    "               steps_per_epoch = len(training_set),\n",
    "               epochs = 1,\n",
    "               validation_data = test_set,\n",
    "               validation_steps = len(test_set))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac54a25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 1s 6ms/step\n",
      "prediction gecti\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "test_set.reset()\n",
    "pred=classifier.predict(test_set,verbose=1)\n",
    "#pred = list(map(round,pred))\n",
    "pred[pred > .5] = 1\n",
    "pred[pred <= .5] = 0\n",
    "\n",
    "print('prediction gecti')\n",
    "#labels = (training_set.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92429bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_labels\n",
      "[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "test_labels = []\n",
    "\n",
    "for i in range(0,int(203)):\n",
    "    test_labels.extend(np.array(test_set[i][1]))\n",
    "    \n",
    "print('test_labels')\n",
    "print(test_labels)\n",
    "\n",
    "#labels = (training_set.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c0ad09e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nidx = []  \\nfor i in test_set:\\n    ixx = (test_set.batch_index - 1) * test_set.batch_size\\n    ixx = test_set.filenames[ixx : ixx + test_set.batch_size]\\n    idx.append(ixx)\\n    print(i)\\n    print(idx)\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "idx = []  \n",
    "for i in test_set:\n",
    "    ixx = (test_set.batch_index - 1) * test_set.batch_size\n",
    "    ixx = test_set.filenames[ixx : ixx + test_set.batch_size]\n",
    "    idx.append(ixx)\n",
    "    print(i)\n",
    "    print(idx)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d547a7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dosyaisimleri = test_set.filenames\n",
    "#abc = test_set.\n",
    "#print(idx)\n",
    "#test_labels = test_set.\n",
    "sonuc = pd.DataFrame()\n",
    "sonuc['dosyaisimleri']= dosyaisimleri\n",
    "sonuc['tahminler'] = pred\n",
    "sonuc['test'] = test_labels   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f84a5e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[137  14]\n",
      " [ 47   5]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "cm = confusion_matrix(test_labels, pred)\n",
    "print (cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fbecc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
